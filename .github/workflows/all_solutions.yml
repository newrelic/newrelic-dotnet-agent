name: All Solutions Build

on:
  pull_request:
    branches:
      - main
      - "feature/**"

  release:
    types: [published]

  workflow_dispatch:
    inputs:
      aggregate_payload_data:
        description: 'Collect and aggregate payload data'
        required: false
        type: boolean
        default: false

  schedule:
    - cron: "0 9 * * 1-5"

# only allow one instance of this workflow to be running per PR or branch, cancels any that are already running
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

env:
  scripts_path: ${{ github.workspace }}\build\scripts
  tools_path: ${{ github.workspace }}\build\Tools
  DOTNET_NOLOGO: true

jobs:
  check-modified-files:
    name: Check if source files were modified, skip remaining jobs if not
    uses: ./.github/workflows/check_modified_files.yml
    secrets: inherit
    permissions:
      contents: read
      pull-requests: read

  shellcheck:
    name: Validate shell scripts
    needs: check-modified-files
    runs-on: ubuntu-latest
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@20cf305ff2072d973412fa9b1e3a4f227bda3c76 # v2.14.0
        with:
          disable-sudo: true
          egress-policy: audit

      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          fetch-depth: 0
      - name: Run Shellcheck
        run: |
          find ${{ github.workspace }} -name "*.sh" -exec shellcheck --severity=error {} +

  # This builds both FullAgent and MSIInstaller since MSIInstaller requires FullAgent artifacts.
  build-fullagent-msi:
    name: Build FullAgent and MSIInstaller
    runs-on: windows-2022
    needs:
      - check-modified-files
      - shellcheck
    # don't run this job if triggered by Dependabot, will cause all other jobs to be skipped as well
    # run this job if source files were modified, or if triggered by a release, a manual execution or schedule
    if: github.actor != 'dependabot[bot]' && (needs.check-modified-files.outputs.source-files-changed == 'true' || github.event.release || github.event_name == 'workflow_dispatch' || github.event_name == 'schedule')

    env:
      fullagent_solution_path: ${{ github.workspace }}\FullAgent.sln
      msi_solution_path: ${{ github.workspace }}\src\Agent\MsiInstaller\MsiInstaller.sln

    outputs:
      agentVersion: ${{ steps.agentVersion.outputs.version }}

    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          fetch-depth: 0

      - name: Setup .NET 10 Preview
        uses: actions/setup-dotnet@2016bd2012dba4e32de620c46fe006a3ac9f0602 # v5.0.1
        with:
          dotnet-version: '10.0.x'
          dotnet-quality: 'ga'
  
      - name: Build FullAgent.sln
        run: |
          Write-Host "dotnet build --force --configuration Release -p:AllowUnsafeBlocks=true ${{ env.fullagent_solution_path }}"
          dotnet build --force --configuration Release -p:AllowUnsafeBlocks=true ${{ env.fullagent_solution_path }}
        shell: powershell

      - name: Create agentVersion
        id: agentVersion
        run: |
          $agentVersion = (Get-Item "${{ github.workspace }}\src\_build\AnyCPU-Release\NewRelic.Agent.Core\net462\NewRelic.Agent.Core.dll").VersionInfo.FileVersion
          echo "version=$agentVersion" >> $env:GITHUB_OUTPUT
        shell: powershell
          
      - name: Archive FullAgent Home folders
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: homefolders
          path: |
            ${{ github.workspace }}\src\Agent\newrelichome_x64
            ${{ github.workspace }}\src\Agent\newrelichome_x64_coreclr
            ${{ github.workspace }}\src\Agent\newrelichome_x64_coreclr_linux
            ${{ github.workspace }}\src\Agent\newrelichome_arm64_coreclr_linux
            ${{ github.workspace }}\src\Agent\newrelichome_x86
            ${{ github.workspace }}\src\Agent\newrelichome_x86_coreclr
          if-no-files-found: error

      - name: Convert Code Signing Certificate Into File
        id: write_cert
        run: |
          $filePath = '${{ github.workspace }}\newrelic_code_sign_cert.pfx'
          $bytes = [Convert]::FromBase64String('${{ secrets.SIGNING_CERT }}')
          [IO.File]::WriteAllBytes($filePath, $bytes)
          echo "filePath=$filePath" >> $env:GITHUB_OUTPUT
        shell: powershell

      - name: Install Code Signing Certificate
        run: |
          Write-Host "certutil.exe -f -user -p <passphrase> -importPFX ${{ steps.write_cert.outputs.filePath }} NoRoot"
          certutil.exe -f -user -p ${{ secrets.CERT_PASSPHRASE }} -importPFX ${{ steps.write_cert.outputs.filePath }} NoRoot
        shell: powershell


      - name: Add msbuild to PATH (required for MsiInstaller build)
        uses: microsoft/setup-msbuild@6fb02220983dee41ce7ae257b6f4d8f9bf5ed4ce # v2.0.0

      - name: Build MsiInstaller.sln x86
        run: |
          Write-Host "MSBuild.exe -restore -m -p:Configuration=Release -p:AllowUnsafeBlocks=true -p:Platform=x86 ${{ env.msi_solution_path }}"
          MSBuild.exe -restore -m -p:Configuration=Release -p:AllowUnsafeBlocks=true -p:Platform=x86 ${{ env.msi_solution_path }}
        shell: powershell

      - name: Build MsiInstaller.sln x64
        run: |
          Write-Host "MSBuild.exe -restore -m -p:Configuration=Release -p:AllowUnsafeBlocks=true -p:Platform=x64 ${{ env.msi_solution_path }}"
          MSBuild.exe -restore -m -p:Configuration=Release -p:AllowUnsafeBlocks=true -p:Platform=x64 ${{ env.msi_solution_path }}
        shell: powershell

      - name: Archive msi _build Artifacts
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: msi-build-folder-artifacts
          path: ${{ github.workspace }}\src\_build
          if-no-files-found: error

  run-linux-container-tests:
    name: Run Linux Container Tests
    needs:
      - build-fullagent-msi
    uses: ./.github/workflows/linux_container_tests.yml
    with:
      aggregate_payload_data: ${{ inputs.aggregate_payload_data == true || github.event_name == 'schedule' }}
    secrets: inherit
    permissions:
      actions: write
      contents: read
        
  build-integration-tests:
    needs: build-fullagent-msi
    name: Build IntegrationTests
    runs-on: windows-2022

    env:
      integration_solution_path: ${{ github.workspace }}\tests\Agent\IntegrationTests\IntegrationTests.sln

    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          fetch-depth: 0

      - name: Setup .NET 10 Preview
        uses: actions/setup-dotnet@2016bd2012dba4e32de620c46fe006a3ac9f0602 # v5.0.1
        with:
          dotnet-version: '10.0.x'
          dotnet-quality: 'ga'
  
      - name: Add msbuild to PATH
        uses: microsoft/setup-msbuild@6fb02220983dee41ce7ae257b6f4d8f9bf5ed4ce # v2.0.0
        with:
          vs-prerelease: true

      - name: List SDKS
        run: dotnet --list-sdks
        shell: powershell

      - name: Build IntegrationTests.sln
        run: |
          Write-Host "List NuGet Sources"
          dotnet nuget list source # For unknown reasons, this step is necessary to avoid subsequent problems with NuGet package restore
          Write-Host "MSBuild.exe -restore -m -p:Configuration=Release -p:DeployOnBuild=true -p:PublishProfile=LocalDeploy ${{ env.integration_solution_path }}"
          MSBuild.exe -restore -m -p:Configuration=Release -p:DeployOnBuild=true -p:PublishProfile=LocalDeploy ${{ env.integration_solution_path }}
        shell: powershell

      - name: Archive Artifacts
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: integrationtests
          path: |
            ${{ github.workspace }}\test.runsettings  # Force the artifacts to use repo root as root of package.
            ${{ github.workspace }}\tests\Agent\IntegrationTests\**\bin\**\*
            ${{ github.workspace }}\tests\Agent\IntegrationTests\**\Deploy\**\*
            !${{ github.workspace }}\tests\Agent\IntegrationTests\**\obj\**\*
          if-no-files-found: error

  build-unbounded-tests:
    needs: build-fullagent-msi
    name: Build UnboundedIntegrationTests
    runs-on: windows-2022

    env:
      unbounded_solution_path: ${{ github.workspace }}\tests\Agent\IntegrationTests\UnboundedIntegrationTests.sln

    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          fetch-depth: 0

      - name: Setup .NET 10 Preview
        uses: actions/setup-dotnet@2016bd2012dba4e32de620c46fe006a3ac9f0602 # v5.0.1
        with:
          dotnet-version: '10.0.x'
          dotnet-quality: 'ga'
  
      - name: Add msbuild to PATH
        uses: microsoft/setup-msbuild@6fb02220983dee41ce7ae257b6f4d8f9bf5ed4ce # v2.0.0
        with:
          vs-prerelease: true

      - name: Build UnboundedIntegrationTests.sln
        run: |
          Write-Host "List NuGet Sources"
          dotnet nuget list source # For unknown reasons, this step is necessary to avoid subsequent problems with NuGet package restore
          Write-Host "MSBuild.exe -restore -m -p:Configuration=Release -p:DeployOnBuild=true -p:PublishProfile=LocalDeploy ${{ env.unbounded_solution_path }}"
          MSBuild.exe -restore -m -p:Configuration=Release -p:DeployOnBuild=true -p:PublishProfile=LocalDeploy ${{ env.unbounded_solution_path }}
        shell: powershell

      - name: Archive Artifacts
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: unboundedintegrationtests
          path: |
            ${{ github.workspace }}\test.runsettings  # Force the artifacts to use repo root as root of package.
            ${{ github.workspace }}\tests\Agent\IntegrationTests\**\bin\**\*
            ${{ github.workspace }}\tests\Agent\IntegrationTests\**\Deploy\**\*
            !${{ github.workspace }}\tests\Agent\IntegrationTests\**\obj\**\*
          if-no-files-found: error

  run-integration-tests:
    needs: [build-integration-tests]
    name: Run IntegrationTests
    runs-on: windows-2022
    strategy:
      matrix:
        namespace: [ 
          AgentFeatures,
          AgentLogs, 
          AgentMetrics, 
          Api, 
          AppDomainCaching, 
          AspNetCore, 
          AwsLambda.AutoInstrumentation,
          AwsLambda.CloudWatch,
          AwsLambda.Custom,
          AwsLambda.DynamoDb,
          AwsLambda.General,
          AwsLambda.Kinesis,
          AwsLambda.S3,
          AwsLambda.Ses,
          AwsLambda.Sns,
          AwsLambda.Sqs,
          AwsLambda.WebRequest,
          AwsSdk,
          AzureFunction,
          BasicInstrumentation, 
          CatInbound, 
          CatOutbound, 
          CodeLevelMetrics, 
          Configuration, 
          CSP, 
          CustomAttributes, 
          CustomInstrumentation, 
          DataTransmission, 
          DistributedTracing, 
          Errors, 
          HttpClientInstrumentation, 
          HybridHttpContextStorage,
          InfiniteTracing,
          LLM,
          Logging.AuditLog,
          Logging.ContextData, 
          Logging.HsmAndCsp, 
          Logging.LocalDecoration, 
          Logging.LogLevelDetection, 
          Logging.MaxSamplesStored, 
          Logging.MetricsAndForwarding, 
          Logging.ZeroMaxSamplesStored,
          OpenTelemetry,
          Owin,
          MassTransit, 
          ReJit.NetCore, 
          ReJit.NetFramework, 
          RequestHandling, 
          RequestHeadersCapture.AspNet, 
          RequestHeadersCapture.AspNetCore, 
          RequestHeadersCapture.EnvironmentVariables, 
          RequestHeadersCapture.Owin, 
          RequestHeadersCapture.WCF, 
          RestSharp, 
          WCF.Client.IIS.ASPDisabled, 
          WCF.Client.IIS.ASPEnabled, 
          WCF.Client.Self, 
          WCF.Service.IIS.ASPDisabled, 
          WCF.Service.IIS.ASPEnabled, 
          WCF.Service.Self] # maintain alphabetical order, please!
      fail-fast: false # we don't want one test failure in one namespace to kill the other runs

    env:
      integration_tests_shared_project: ${{ github.workspace }}/tests/Agent/IntegrationTests/Shared
      integration_tests_path: ${{ github.workspace }}/tests/Agent/IntegrationTests/IntegrationTests/bin/Release/net10.0
      # Make this variable true to enable extra data-gathering and logging to help troubleshoot test failures, at the cost of additional time and resources
      enhanced_logging: false
      NR_DOTNET_TEST_SAVE_WORKING_DIRECTORY: 1
      azure_func_exe_path: C:\ProgramData\chocolatey\lib\azure-functions-core-tools\tools\func.exe
      NEW_RELIC_AZURE_FUNCTION_LOG_LEVEL_OVERRIDE: 1 # enables profiler debug logs when testing an azure function
      # Set an environment variable that the tests will use to set the application name.
      CI_NEW_RELIC_APP_NAME: ${{ github.event_name == 'schedule' && 'DotNetIngestTracking' || '' }}
    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          fetch-depth: 0

      - name: Setup .NET 10 Preview
        uses: actions/setup-dotnet@2016bd2012dba4e32de620c46fe006a3ac9f0602 # v5.0.1
        with:
          dotnet-version: '10.0.x'
          dotnet-quality: 'ga'
  
      - name: Disable TLS 1.3
        run: |
          $registryPath = "HKLM:\SYSTEM\CurrentControlSet\Control\SecurityProviders\SCHANNEL\Protocols\TLS 1.3\Client"
          if(!(Test-Path $registryPath)) {
            New-Item -Path $registryPath -Force
          }
          New-ItemProperty -Path $registryPath -Name "DisabledByDefault" -Value "1" -PropertyType DWORD -Force
          New-ItemProperty -Path $registryPath -Name "Enabled" -Value "0" -PropertyType DWORD -Force
        shell: powershell

      - name: Create and trust .NET development SSL certificate
        run: |
          dotnet dev-certs https --clean
          dotnet dev-certs https --export-path ./devcert.pfx --password "password1"
          $pwd = ConvertTo-SecureString -String "password1" -Force -AsPlainText
          Import-PfxCertificate -FilePath ./devcert.pfx -CertStoreLocation Cert:\LocalMachine\Root -Password $pwd
          dotnet dev-certs https --check --trust
        shell: powershell

      - name: Set up secrets
        env:
          INTEGRATION_TEST_SECRETS: ${{ secrets.TEST_SECRETS }}
        run: |
          "$Env:INTEGRATION_TEST_SECRETS" | dotnet user-secrets set --project ${{ env.integration_tests_shared_project }}
        shell: pwsh #this doesn't work with normal powershell due to UTF-8 BOM handling

      - name: Download Agent Home Folders
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: homefolders
          path: src/Agent

      - name: Download Integration Test Artifacts
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: integrationtests
          # Should not need a path because the integration test artifacts are archived with the full directory structure

      - name: Install HostableWebCore Feature
        if: | # only install for the required namespaces
          matrix.namespace == 'AgentFeatures' || matrix.namespace == 'AgentLogs' || matrix.namespace == 'AgentMetrics' || matrix.namespace == 'BasicInstrumentation' || 
          matrix.namespace == 'CatInbound' || matrix.namespace == 'CatOutbound' || matrix.namespace == 'CodeLevelMetrics' || matrix.namespace == 'CSP' || 
          matrix.namespace == 'CustomAttributes' || matrix.namespace == 'CustomInstrumentation' || matrix.namespace == 'DataTransmission' || 
          matrix.namespace == 'DistributedTracing' || matrix.namespace == 'Errors' || matrix.namespace == 'HttpClientInstrumentation' || matrix.namespace == 'HybridHttpContextStorage' ||
          matrix.namespace == 'Rejit.NetFramework' || matrix.namespace == 'RequestHandling' || matrix.namespace == 'RequestHeadersCapture.AspNet' ||
          matrix.namespace == 'RequestHeadersCapture.AspNetCore' || matrix.namespace == 'RequestHeadersCapture.EnvironmentVariables' ||
          matrix.namespace == 'RequestHeadersCapture.WCF' || matrix.namespace == 'WCF.Client.IIS.ASPDisabled' ||
          matrix.namespace == 'WCF.Client.IIS.ASPEnabled' || matrix.namespace == 'WCF.Service.IIS.ASPDisabled' ||
          matrix.namespace == 'WCF.Service.IIS.ASPEnabled'
        run: |
          Enable-WindowsOptionalFeature -Online -FeatureName IIS-HostableWebCore
        shell: powershell

      - name: Install aiohttp
        if: matrix.namespace == 'DistributedTracing'
        run: |
          pip install aiohttp
        shell: powershell

      - name: Install Azure Functions Core Tools
        if: matrix.namespace == 'AzureFunction'
        run: |
          choco install azure-functions-core-tools -y --params "'/x64'"
        shell: powershell

      - name: Setup .NET 10 Preview
        uses: actions/setup-dotnet@2016bd2012dba4e32de620c46fe006a3ac9f0602 # v5.0.1
        with:
          dotnet-version: '10.0.x'
          dotnet-quality: 'ga'
  
      - name: Run Integration Tests
        run: |
          if ($Env:enhanced_logging -eq $True) {
            Write-Host "List ports in use"
            netstat -no
          }

          Write-Host "Run tests"

          # Test parallelization is disabled until we can solve concurrent dotnet publish issues with ConsoleMF usage
          $json = Get-Content "${{ env.integration_tests_path }}/xunit.runner.json" | ConvertFrom-Json
          $json | Add-Member -Name "parallelizeAssembly" -Value $false -MemberType NoteProperty
          $json | Add-Member -Name "parallelizeTestCollections" -Value $false -MemberType NoteProperty
          # if ("${{ matrix.namespace }}" -like "Logging.*" ) {
          #   $json.parallelizeAssembly = $true
          #   $json.parallelizeTestCollections = $true
          # }
          $json | ConvertTo-Json | Out-File "${{ env.integration_tests_path }}/xunit.runner.json"

          ${{ env.integration_tests_path }}/NewRelic.Agent.IntegrationTests.exe -namespace NewRelic.Agent.IntegrationTests.${{ matrix.namespace }} -trx "C:\IntegrationTestWorkingDirectory\TestResults\${{ matrix.namespace }}_testResults.trx"

          if ($Env:enhanced_logging -eq $True) {
            Write-Host "Get HostableWebCore errors (if any)"
            Get-EventLog -LogName Application -Source HostableWebCore -ErrorAction:Ignore

            Write-Host "Get .NET Runtime errors (if any)"
            Get-EventLog -LogName Application -Source ".NET Runtime" -EntryType "Error","Warning" -ErrorAction:Ignore
          }
        shell: powershell

      - name: Extract payload bytes log from TRX
        if: inputs.aggregate_payload_data == true || github.event_name == 'schedule'
        run: |
          $trxFile = "C:\IntegrationTestWorkingDirectory\TestResults\${{ matrix.namespace }}_testResults.trx"
          $payloadLog = "C:\IntegrationTestWorkingDirectory\TestResults\${{ matrix.namespace }}_payload_bytes.json"

          Write-Host "Checking for TRX file at: $trxFile"

          if (Test-Path $trxFile) {
            $fileSize = (Get-Item $trxFile).Length
            Write-Host "TRX file found. Size: $fileSize bytes"

            # Read TRX file and extract lines containing payload information from Message elements
            [xml]$trxContent = Get-Content $trxFile
            $messageElements = $trxContent.SelectNodes("//*[local-name()='Output']/*[local-name()='TextMessages']/*[local-name()='Message']")

            $payloadData = @{}
            foreach ($message in $messageElements) {
              $text = $message.InnerText
              if ($text -match "^(.+?):\s*Total payload bytes sent:\s*(\d+)") {
                $className = $Matches[1].Trim()
                $byteCount = [int]$Matches[2]
                $payloadData[$className] = $byteCount
                Write-Host "Found: $className = $byteCount bytes"
              }
            }

            Write-Host "Found $($payloadData.Count) payload log entries"

            if ($payloadData.Count -gt 0) {
              $payloadData | ConvertTo-Json | Out-File -FilePath $payloadLog -Encoding UTF8
              Write-Host "Extracted payload logs to $payloadLog"
              Write-Host "Content:"
              Get-Content $payloadLog | ForEach-Object { Write-Host $_ }
            } else {
              Write-Host "No payload byte logs found in TRX file"
              @{} | ConvertTo-Json | Out-File -FilePath $payloadLog -Encoding UTF8
            }
          } else {
            Write-Host "TRX file not found"
            @{} | ConvertTo-Json | Out-File -FilePath $payloadLog -Encoding UTF8
          }
        shell: powershell

      - name: Upload payload bytes log
        if: inputs.aggregate_payload_data == true || github.event_name == 'schedule'
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: integration-payload-bytes-${{ matrix.namespace }}
          path: C:\IntegrationTestWorkingDirectory\TestResults\*_payload_bytes.json
          if-no-files-found: warn

      - name: Archive integration test results on failure
        if: ${{ failure() }}
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: integration-test-results-${{ matrix.namespace }}
          path: |
            C:\IntegrationTestWorkingDirectory\**\*.log
            C:\IntegrationTestWorkingDirectory\**\*.config
            C:\IntegrationTestWorkingDirectory\TestResults\**\*TestResults.trx
          if-no-files-found: error

  run-unbounded-tests:
    needs: [build-unbounded-tests]
    name: Run Unbounded Tests
    runs-on: windows-2022
    strategy:
      matrix:
        namespace:
          [
            AzureServiceBus,
            CosmosDB,
            Couchbase,
            Elasticsearch,
            MongoDB,
            Msmq,
            MsSql,
            MySql,
            NServiceBus,
            NServiceBus5,
            Oracle,
            Postgres,
            RabbitMq,
            Redis,
          ]
      fail-fast: false # we don't want one test failure in one namespace to kill the other runs

    env:
      integration_tests_shared_project: ${{ github.workspace }}/tests/Agent/IntegrationTests/Shared
      unbounded_tests_path: ${{ github.workspace }}/tests/Agent/IntegrationTests/UnboundedIntegrationTests/bin/Release/net10.0
      NR_DOTNET_TEST_SAVE_WORKING_DIRECTORY: 1
      # Make this variable true to enable extra data-gathering and logging to help troubleshoot test failures, at the cost of additional time and resources
      enhanced_logging: false
      # Set an environment variable that the tests will use to set the application name.
      CI_NEW_RELIC_APP_NAME: ${{ github.event_name == 'schedule' && 'DotNetIngestTracking' || '' }}

    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          fetch-depth: 0

      - name: Download Agent Home Folders
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: homefolders
          path: src/Agent

      - name: Download Unbounded Integration Test Artifacts
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: unboundedintegrationtests
          # Should not need a path because the integration test artifacts are archived with the full directory structure

      - name: Disable TLS 1.3
        run: |
          $registryPath = "HKLM:\SYSTEM\CurrentControlSet\Control\SecurityProviders\SCHANNEL\Protocols\TLS 1.3\Client"
          if(!(Test-Path $registryPath)) {
            New-Item -Path $registryPath -Force
          }
          New-ItemProperty -Path $registryPath -Name "DisabledByDefault" -Value "1" -PropertyType DWORD -Force
          New-ItemProperty -Path $registryPath -Name "Enabled" -Value "0" -PropertyType DWORD -Force
        shell: powershell

      - name: Install HostableWebCore Feature
        if: | # only install for the required namespaces
          matrix.namespace == 'MongoDB' || matrix.namespace == 'MsSql' || matrix.namespace == 'Oracle'
        run: |
          Enable-WindowsOptionalFeature -Online -FeatureName IIS-HostableWebCore
        shell: powershell

      - name: Install MSMQ dependencies
        if: matrix.namespace == 'Msmq'
        run: |
          Write-Host "Installing Msmq Features"
          Enable-WindowsOptionalFeature -Online -FeatureName MSMQ-Server -All
          Enable-WindowsOptionalFeature -Online -FeatureName MSMQ-HTTP -All
          Enable-WindowsOptionalFeature -Online -FeatureName MSMQ-Triggers -All
        shell: powershell

      - name: Install MsSql dependencies
        if: matrix.namespace == 'MsSql'
        run: |
          Write-Host "Installing MSSQL CLI"
          msiexec /i "${{ github.workspace }}\build\Tools\sqlncli.msi" IACCEPTSQLNCLILICENSETERMS=YES /quiet /qn /norestart
          Start-Sleep 20 # Need to wait for install to finish -- takes only a few seconds, but we need to be sure.
        shell: powershell

      - name: Set up secrets
        env:
          INTEGRATION_TEST_SECRETS: ${{ secrets.TEST_SECRETS }}
        run: |
          "$Env:INTEGRATION_TEST_SECRETS" | dotnet user-secrets set --project ${{ env.integration_tests_shared_project }}
        shell: pwsh #this doesn't work with normal powershell due to UTF-8 BOM handling
        
# save in case we move back to using the emulator
#      - name: Start Local CosmosDB Emulator for CosmosDB Tests
#        if: matrix.namespace == 'CosmosDB'
#        run: |
#          Write-Host "Launching Cosmos DB Emulator"
#          Import-Module "$env:ProgramFiles\Azure Cosmos DB Emulator\PSModules\Microsoft.Azure.CosmosDB.Emulator"
#          Start-CosmosDbEmulator
#        shell: pwsh

      - name: Setup .NET 10 Preview
        uses: actions/setup-dotnet@2016bd2012dba4e32de620c46fe006a3ac9f0602 # v5.0.1
        with:
          dotnet-version: '10.0.x'
          dotnet-quality: 'ga'
  
      - name: Run Unbounded Integration Tests
        run: |
          if ($Env:enhanced_logging -eq $True) {
            Write-Host "List ports in use"
            netstat -no
          }

          # Test parallelization is disabled until we can solve concurrent dotnet publish issues with ConsoleMF usage
          $json = Get-Content "${{ env.unbounded_tests_path }}/xunit.runner.json" | ConvertFrom-Json
          $json | Add-Member -Name "parallelizeAssembly" -Value $false -MemberType NoteProperty
          $json | Add-Member -Name "parallelizeTestCollections" -Value $false -MemberType NoteProperty
          $json | ConvertTo-Json | Out-File "${{ env.unbounded_tests_path }}/xunit.runner.json"

          ${{ env.unbounded_tests_path }}/NewRelic.Agent.UnboundedIntegrationTests.exe -namespace NewRelic.Agent.UnboundedIntegrationTests.${{ matrix.namespace }} -trx "C:\IntegrationTestWorkingDirectory\TestResults\${{ matrix.namespace }}_testResults.trx"

          if ($Env:enhanced_logging -eq $True) {
            Write-Host "Get HostableWebCore errors (if any)"
            Get-EventLog -LogName Application -Source HostableWebCore -ErrorAction:Ignore

            Write-Host "Get .NET Runtime errors (if any)"
            Get-EventLog -LogName Application -Source ".NET Runtime" -EntryType "Error","Warning" -ErrorAction:Ignore
          }
        shell: powershell

      - name: Extract payload bytes log from TRX
        if: inputs.aggregate_payload_data == true || github.event_name == 'schedule'
        run: |
          $trxFile = "C:\IntegrationTestWorkingDirectory\TestResults\${{ matrix.namespace }}_testResults.trx"
          $payloadLog = "C:\IntegrationTestWorkingDirectory\TestResults\${{ matrix.namespace }}_payload_bytes.json"

          Write-Host "Checking for TRX file at: $trxFile"

          if (Test-Path $trxFile) {
            $fileSize = (Get-Item $trxFile).Length
            Write-Host "TRX file found. Size: $fileSize bytes"

            # Read TRX file and extract lines containing payload information from Message elements
            [xml]$trxContent = Get-Content $trxFile
            $messageElements = $trxContent.SelectNodes("//*[local-name()='Output']/*[local-name()='TextMessages']/*[local-name()='Message']")

            $payloadData = @{}
            foreach ($message in $messageElements) {
              $text = $message.InnerText
              if ($text -match "^(.+?):\s*Total payload bytes sent:\s*(\d+)") {
                $className = $Matches[1].Trim()
                $byteCount = [int]$Matches[2]
                $payloadData[$className] = $byteCount
                Write-Host "Found: $className = $byteCount bytes"
              }
            }

            Write-Host "Found $($payloadData.Count) payload log entries"

            if ($payloadData.Count -gt 0) {
              $payloadData | ConvertTo-Json | Out-File -FilePath $payloadLog -Encoding UTF8
              Write-Host "Extracted payload logs to $payloadLog"
              Write-Host "Content:"
              Get-Content $payloadLog | ForEach-Object { Write-Host $_ }
            } else {
              Write-Host "No payload byte logs found in TRX file"
              @{} | ConvertTo-Json | Out-File -FilePath $payloadLog -Encoding UTF8
            }
          } else {
            Write-Host "TRX file not found"
            @{} | ConvertTo-Json | Out-File -FilePath $payloadLog -Encoding UTF8
          }
        shell: powershell

      - name: Upload payload bytes log
        if: inputs.aggregate_payload_data == true || github.event_name == 'schedule'
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: unbounded-payload-bytes-${{ matrix.namespace }}
          path: C:\IntegrationTestWorkingDirectory\TestResults\*_payload_bytes.json
          if-no-files-found: warn

      - name: Archive unbounded test results on failure
        if: ${{ failure() }}
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: unbounded-test-working-directory-${{ matrix.namespace }}
          path: |
            C:\IntegrationTestWorkingDirectory\**\*.log
            C:\IntegrationTestWorkingDirectory\**\*.config
            C:\IntegrationTestWorkingDirectory\TestResults\**\*TestResults.trx
          if-no-files-found: error

  create-package-rpm:
    needs: build-fullagent-msi
    name: Create RPM Package
    runs-on: ubuntu-22.04

    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@20cf305ff2072d973412fa9b1e3a4f227bda3c76 # v2.14.0
        with:
          disable-sudo: true
          egress-policy: audit

      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          fetch-depth: 0

      - name: Download msi _build Artifacts
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: msi-build-folder-artifacts
          path: src/_build

      - name: Download Agent Home Folders
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: homefolders
          path: src/Agent

      - name: Convert GPG Private Key Into File
        id: write_gpgkey
        run: |
          filePath="/tmp/private_gpg_key.gpg"
          echo "${{ secrets.NEW_GPG_KEY }}" | base64 -d > $filePath
          echo "filePath=$filePath" >> $GITHUB_OUTPUT
        shell: bash

      - name: Copy GPG Key to keys
        run: |
          mkdir ${{ github.workspace }}/build/Linux/keys
          cp -f ${{ steps.write_gpgkey.outputs.filePath }} ${{ github.workspace }}/build/Linux/keys/private_gpg_key.gpg
        shell: bash

      - name: Build RPM
        run: |
          agentVersion=${{ needs.build-fullagent-msi.outputs.agentVersion }}

          if [[ "$agentVersion" =~ [0-9]+\.[0-9]+\.[0-9]+\.[0-9]+ ]]; then
            major=$(echo $agentVersion | cut -d'.' -f1)
            minor=$(echo $agentVersion | cut -d'.' -f2)
            patch=$(echo $agentVersion | cut -d'.' -f3)
            agentVersion="${major}.${minor}.${patch}"
            echo "agentVersion is simplified to $agentVersion"
          fi

          cd ${{ github.workspace }}/build/Linux
          docker compose build build_rpm
          docker compose run -e AGENT_VERSION=$agentVersion -e GPG_KEY=/keys/private_gpg_key.gpg -e GPG_KEY_PASSPHRASE=${{ secrets.NEW_GPG_KEY_PASSPHRASE }} build_rpm
        shell: bash

      - name: Archive RPM Package Artifacts
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: rpm-build-artifacts
          path: ${{ github.workspace }}/src/_build/CoreArtifacts
          if-no-files-found: error

  create-package-deb:
    needs: build-fullagent-msi
    name: Create Debian package
    runs-on: ubuntu-22.04

    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@20cf305ff2072d973412fa9b1e3a4f227bda3c76 # v2.14.0
        with:
          disable-sudo: true
          egress-policy: audit

      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          fetch-depth: 0

      - name: Download Agent Home Folders
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: homefolders
          path: src/Agent

      - name: Download msi _build Artifacts
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: msi-build-folder-artifacts
          path: src/_build

      - name: Build Debian Package
        run: |
          agentVersion=${{ needs.build-fullagent-msi.outputs.agentVersion }}

          if [[ "$agentVersion" =~ [0-9]+\.[0-9]+\.[0-9]+\.[0-9]+ ]]; then
            major=$(echo $agentVersion | cut -d'.' -f1)
            minor=$(echo $agentVersion | cut -d'.' -f2)
            patch=$(echo $agentVersion | cut -d'.' -f3)
            agentVersion="${major}.${minor}.${patch}"
            echo "agentVersion is simplified to $agentVersion"
          fi

          cd ${{ github.workspace }}/build/Linux
          docker compose build build_deb
          docker compose run -e AGENT_VERSION=$agentVersion build_deb
        shell: bash

      - name: Archive Debian Package Artifacts
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: debian-build-artifacts
          path: ${{ github.workspace }}/src/_build/CoreArtifacts
          if-no-files-found: error

  run-artifactbuilder:
    needs: [create-package-rpm, create-package-deb]
    name: Run ArtifactBuilder
    runs-on: windows-2022

    steps:
      - name: Setup .NET 10 Preview
        uses: actions/setup-dotnet@2016bd2012dba4e32de620c46fe006a3ac9f0602 # v5.0.1
        with:
          dotnet-version: '10.0.x'
          dotnet-quality: 'ga'
  
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          fetch-depth: 0

      - name: Download Agent Home Folders
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: homefolders
          path: src/Agent

      - name: Download msi _build Artifacts
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: msi-build-folder-artifacts
          path: src/_build

      - name: Download Debian _build Artifacts
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: debian-build-artifacts
          path: src/_build/CoreArtifacts

      - name: Download RPM _build Artifacts
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: rpm-build-artifacts
          path: src/_build/CoreArtifacts

      - name: Add msbuild to PATH
        uses: microsoft/setup-msbuild@6fb02220983dee41ce7ae257b6f4d8f9bf5ed4ce # v2.0.0
        
      - name: Build NewRelic.NuGetHelper
        run: |
          MSBuild.exe -restore -m -p:Configuration=Release ${{ github.workspace }}\build\NewRelic.NuGetHelper\NewRelic.NuGetHelper.csproj  
        shell: powershell

      - name: Run ArtifactBuilder
        run: |
          ${{ github.workspace }}\build\package.ps1 -configuration Release -IncludeDownloadSite
        shell: powershell

      - name: Archive Deploy Artifacts
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: deploy-artifacts
          path: |
            ${{ github.workspace }}\build\BuildArtifacts
          if-no-files-found: error

  # This job is necessary in order for us to have a branch protection rule for tests with a matrix
  # if any of the matrix tests fail, this job fails and the branch protection rule keeps the PR from merging
  integration-test-status:
    name: Check Test Matrix Status
    runs-on: ubuntu-latest
    needs: [run-linux-container-tests, run-integration-tests, run-unbounded-tests]
    if: always()
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@20cf305ff2072d973412fa9b1e3a4f227bda3c76 # v2.14.0
        with:
          disable-sudo: true
          egress-policy: audit
      - name: Successful test run
        if: ${{ !(contains(needs.*.result, 'failure')) }}
        run: exit 0
      - name: Failing test run
        if: ${{ contains(needs.*.result, 'failure') }}
        run: exit 1

  aggregate-integration-payload-logs:
    name: Aggregate Integration Test Payload Logs
    needs: [integration-test-status]
    runs-on: ubuntu-latest
    if: inputs.aggregate_payload_data == true || github.event_name == 'schedule'
    permissions:
      actions: write
      contents: read
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@20cf305ff2072d973412fa9b1e3a4f227bda3c76 # v2.14.0
        with:
          disable-sudo: true
          egress-policy: audit

      - name: Download all integration payload artifacts
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          pattern: integration-payload-bytes-*
          path: payload-logs/integration
          merge-multiple: true

      - name: Combine payload logs
        run: |
          mkdir -p combined-logs

          if [ -d "payload-logs/integration" ]; then
            echo "["  > combined-logs/integration_payload_bytes_combined.json
            first=true
            grand_total=0

            # Process JSON files and merge into array
            while IFS= read -r file; do
              echo "Processing: $(basename "$file")"

              # Read JSON and extract key-value pairs
              while IFS= read -r line; do
                # Skip lines that are just braces or empty
                if [[ "$line" =~ ^[[:space:]]*\{[[:space:]]*$ ]] || [[ "$line" =~ ^[[:space:]]*\}[[:space:]]*$ ]] || [[ -z "$line" ]]; then
                  continue
                fi

                # Extract class name and byte count from JSON property
                if [[ "$line" =~ \"([^\"]+)\":[[:space:]]*([0-9]+) ]]; then
                  className="${BASH_REMATCH[1]}"
                  byteCount="${BASH_REMATCH[2]}"
                  grand_total=$((grand_total + byteCount))

                  if [ "$first" = true ]; then
                    first=false
                  else
                    echo "," >> combined-logs/integration_payload_bytes_combined.json
                  fi
                  echo "  {\"className\": \"$className\", \"payloadBytes\": $byteCount}" >> combined-logs/integration_payload_bytes_combined.json
                fi
              done < "$file"
            done < <(find payload-logs/integration -name "*_payload_bytes.json" -type f | sort)

            echo "" >> combined-logs/integration_payload_bytes_combined.json
            echo "]" >> combined-logs/integration_payload_bytes_combined.json

            # Create summary metadata file
            echo "{" > combined-logs/integration_payload_bytes_summary.json
            echo "  \"testType\": \"Integration Tests\"," >> combined-logs/integration_payload_bytes_summary.json
            echo "  \"generatedAt\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\"," >> combined-logs/integration_payload_bytes_summary.json
            echo "  \"grandTotalBytes\": $grand_total" >> combined-logs/integration_payload_bytes_summary.json
            echo "}" >> combined-logs/integration_payload_bytes_summary.json

            echo "Combined payload JSON created with grand total: $grand_total bytes"
            echo "Payload data:"
            cat combined-logs/integration_payload_bytes_combined.json
            echo ""
            echo "Summary:"
            cat combined-logs/integration_payload_bytes_summary.json
          else
            echo "No integration payload logs found"
            echo "[]" > combined-logs/integration_payload_bytes_combined.json
            echo "{\"testType\": \"Integration Tests\", \"grandTotalBytes\": 0}" > combined-logs/integration_payload_bytes_summary.json
          fi
        shell: bash

      - name: Upload combined integration payload log
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: combined-integration-payload-bytes
          path: combined-logs/integration_payload_bytes_*.json
          if-no-files-found: warn

      - name: Delete individual integration payload artifacts
        run: |
          # Get all artifacts matching the pattern and delete them
          gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts \
            --jq '.artifacts[] | select(.name | startswith("integration-payload-bytes-")) | .name' \
            | while read -r artifact_name; do
              echo "Deleting artifact: $artifact_name"
              gh api repos/${{ github.repository }}/actions/artifacts \
                --jq ".artifacts[] | select(.name == \"$artifact_name\" and .workflow_run.id == ${{ github.run_id }}) | .id" \
                | while read -r artifact_id; do
                  gh api --method DELETE repos/${{ github.repository }}/actions/artifacts/$artifact_id || echo "Failed to delete $artifact_name"
                done
            done
        env:
          GH_TOKEN: ${{ github.token }}
        shell: bash
        continue-on-error: true

  aggregate-unbounded-payload-logs:
    name: Aggregate Unbounded Test Payload Logs
    needs: [integration-test-status]
    runs-on: ubuntu-latest
    if: inputs.aggregate_payload_data == true || github.event_name == 'schedule'
    permissions:
      actions: write
      contents: read
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@20cf305ff2072d973412fa9b1e3a4f227bda3c76 # v2.14.0
        with:
          disable-sudo: true
          egress-policy: audit

      - name: Download all unbounded payload artifacts
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          pattern: unbounded-payload-bytes-*
          path: payload-logs/unbounded
          merge-multiple: true

      - name: Combine payload logs
        run: |
          mkdir -p combined-logs

          if [ -d "payload-logs/unbounded" ]; then
            echo "["  > combined-logs/unbounded_payload_bytes_combined.json
            first=true
            grand_total=0

            # Process JSON files and merge into array
            while IFS= read -r file; do
              echo "Processing: $(basename "$file")"

              # Read JSON and extract key-value pairs
              while IFS= read -r line; do
                # Skip lines that are just braces or empty
                if [[ "$line" =~ ^[[:space:]]*\{[[:space:]]*$ ]] || [[ "$line" =~ ^[[:space:]]*\}[[:space:]]*$ ]] || [[ -z "$line" ]]; then
                  continue
                fi

                # Extract class name and byte count from JSON property
                if [[ "$line" =~ \"([^\"]+)\":[[:space:]]*([0-9]+) ]]; then
                  className="${BASH_REMATCH[1]}"
                  byteCount="${BASH_REMATCH[2]}"
                  grand_total=$((grand_total + byteCount))

                  if [ "$first" = true ]; then
                    first=false
                  else
                    echo "," >> combined-logs/unbounded_payload_bytes_combined.json
                  fi
                  echo "  {\"className\": \"$className\", \"payloadBytes\": $byteCount}" >> combined-logs/unbounded_payload_bytes_combined.json
                fi
              done < "$file"
            done < <(find payload-logs/unbounded -name "*_payload_bytes.json" -type f | sort)

            echo "" >> combined-logs/unbounded_payload_bytes_combined.json
            echo "]" >> combined-logs/unbounded_payload_bytes_combined.json

            # Create summary metadata file
            echo "{" > combined-logs/unbounded_payload_bytes_summary.json
            echo "  \"testType\": \"Unbounded Integration Tests\"," >> combined-logs/unbounded_payload_bytes_summary.json
            echo "  \"generatedAt\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\"," >> combined-logs/unbounded_payload_bytes_summary.json
            echo "  \"grandTotalBytes\": $grand_total" >> combined-logs/unbounded_payload_bytes_summary.json
            echo "}" >> combined-logs/unbounded_payload_bytes_summary.json

            echo "Combined payload JSON created with grand total: $grand_total bytes"
            echo "Payload data:"
            cat combined-logs/unbounded_payload_bytes_combined.json
            echo ""
            echo "Summary:"
            cat combined-logs/unbounded_payload_bytes_summary.json
          else
            echo "No unbounded payload logs found"
            echo "[]" > combined-logs/unbounded_payload_bytes_combined.json
            echo "{\"testType\": \"Unbounded Integration Tests\", \"grandTotalBytes\": 0}" > combined-logs/unbounded_payload_bytes_summary.json
          fi
        shell: bash

      - name: Upload combined unbounded payload log
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: combined-unbounded-payload-bytes
          path: combined-logs/unbounded_payload_bytes_*.json
          if-no-files-found: warn

      - name: Delete individual unbounded payload artifacts
        run: |
          # Get all artifacts matching the pattern and delete them
          gh api repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts \
            --jq '.artifacts[] | select(.name | startswith("unbounded-payload-bytes-")) | .name' \
            | while read -r artifact_name; do
              echo "Deleting artifact: $artifact_name"
              gh api repos/${{ github.repository }}/actions/artifacts \
                --jq ".artifacts[] | select(.name == \"$artifact_name\" and .workflow_run.id == ${{ github.run_id }}) | .id" \
                | while read -r artifact_id; do
                  gh api --method DELETE repos/${{ github.repository }}/actions/artifacts/$artifact_id || echo "Failed to delete $artifact_name"
                done
            done
        env:
          GH_TOKEN: ${{ github.token }}
        shell: bash
        continue-on-error: true

  display-all-payload-summaries:
    name: Display All Payload Summaries
    needs: [aggregate-integration-payload-logs, aggregate-unbounded-payload-logs, run-linux-container-tests]
    runs-on: ubuntu-latest
    if: inputs.aggregate_payload_data == true || github.event_name == 'schedule'
    permissions:
      contents: read
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@20cf305ff2072d973412fa9b1e3a4f227bda3c76 # v2.14.0
        with:
          disable-sudo: true
          egress-policy: audit

      - name: Download combined integration payload log
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: combined-integration-payload-bytes
          path: payload-summaries
        continue-on-error: true

      - name: Download combined unbounded payload log
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: combined-unbounded-payload-bytes
          path: payload-summaries
        continue-on-error: true

      - name: Download combined Linux container payload log
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: combined-linux-container-payload-bytes
          path: payload-summaries
        continue-on-error: true

      - name: Create consolidated JSON output
        run: |
          if [ -d "payload-summaries" ]; then
            echo "{"  > final_payload_summary.json

            first_type=true
            overall_total=0

            # Process each test type's combined data
            for data_file in payload-summaries/*_combined.json; do
              if [ -f "$data_file" ]; then
                filename=$(basename "$data_file" _payload_bytes_combined.json)

                # Determine test type name
                case "$filename" in
                  integration)
                    test_type="integrationTests"
                    ;;
                  unbounded)
                    test_type="unboundedTests"
                    ;;
                  linux_container)
                    test_type="containerTests"
                    ;;
                  *)
                    test_type="$filename"
                    ;;
                esac

                # Get corresponding summary file for grand total and timestamp
                summary_file="payload-summaries/${filename}_payload_bytes_summary.json"
                grand_total=0
                generated_at=""
                if [ -f "$summary_file" ]; then
                  if grep -q "grandTotalBytes" "$summary_file"; then
                    grand_total=$(grep -oP '"grandTotalBytes":\s*\K\d+' "$summary_file")
                    overall_total=$((overall_total + grand_total))
                  fi
                  if grep -q "generatedAt" "$summary_file"; then
                    generated_at=$(grep -oP '"generatedAt":\s*"\K[^"]+' "$summary_file")
                  fi
                fi

                # Add comma separator if not first entry
                if [ "$first_type" = false ]; then
                  echo "," >> final_payload_summary.json
                fi
                first_type=false

                # Add test type section
                echo "  \"$test_type\": {" >> final_payload_summary.json
                echo "    \"generatedAt\": \"$generated_at\"," >> final_payload_summary.json
                echo "    \"bytes\": $grand_total," >> final_payload_summary.json
                echo "    \"details\": [" >> final_payload_summary.json

                # Read and merge test class data from combined file, converting payloadBytes to bytes
                first_test=true
                while IFS= read -r line; do
                  # Skip array brackets and empty lines
                  if [[ "$line" =~ ^[[:space:]]*\[[[:space:]]*$ ]] || [[ "$line" =~ ^[[:space:]]*\][[:space:]]*$ ]] || [[ -z "$line" ]]; then
                    continue
                  fi

                  # Extract className and payloadBytes, convert to new format
                  if [[ "$line" =~ \"className\":[[:space:]]*\"([^\"]+)\".*\"payloadBytes\":[[:space:]]*([0-9]+) ]]; then
                    className="${BASH_REMATCH[1]}"
                    byteCount="${BASH_REMATCH[2]}"

                    # Add comma separator if not first test entry
                    if [ "$first_test" = false ]; then
                      echo "," >> final_payload_summary.json
                    fi
                    first_test=false

                    echo "      {\"className\": \"$className\", \"bytes\": $byteCount}" >> final_payload_summary.json
                  fi
                done < "$data_file"

                echo "" >> final_payload_summary.json
                echo "    ]" >> final_payload_summary.json
                echo -n "  }" >> final_payload_summary.json
              fi
            done

            echo "," >> final_payload_summary.json
            echo "  \"bytes\": $overall_total" >> final_payload_summary.json
            echo "}" >> final_payload_summary.json

            echo "=========================================="
            echo "FINAL CONSOLIDATED PAYLOAD SUMMARY"
            echo "=========================================="
            cat final_payload_summary.json
            echo ""
            echo "=========================================="
            echo "OVERALL TOTAL: $overall_total bytes"
            echo "=========================================="
          else
            echo "No payload summary files found"
            echo '{"bytes": 0}' > final_payload_summary.json
          fi
        shell: bash

      - name: Upload final consolidated summary
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: final-payload-summary
          path: final_payload_summary.json
          if-no-files-found: warn

      - name: Delete combined payload artifacts
        run: |
          # Delete the combined artifacts explicitly
          for artifact_name in combined-integration-payload-bytes combined-unbounded-payload-bytes combined-linux-container-payload-bytes; do
            echo "Deleting artifact: $artifact_name"
            gh api repos/${{ github.repository }}/actions/artifacts \
              --jq ".artifacts[] | select(.name == \"$artifact_name\" and .workflow_run.id == ${{ github.run_id }}) | .id" \
              | while read -r artifact_id; do
                gh api --method DELETE repos/${{ github.repository }}/actions/artifacts/$artifact_id || echo "Failed to delete $artifact_name"
              done
          done
        env:
          GH_TOKEN: ${{ github.token }}
        shell: bash
        continue-on-error: true
